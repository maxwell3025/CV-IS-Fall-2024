{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature visualization (Tensorflow)"
   ],
   "id": "544e8b9dca51f55f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of feature visualization with a Tensorflow model. The feature visualization in OmniXAI is an optimization-based method, allowing to set different objectives, e.g., layer, channel, neuron or direction. For more information, please visit https://distill.pub/2017/feature-visualization/"
   ],
   "id": "6a3c5c77b47507c9"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T06:48:13.586618Z",
     "start_time": "2024-10-16T06:48:13.469004Z"
    }
   },
   "source": [
    "# This default renderer is used for sphinx docs only. Please delete this cell in IPython.\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"png\""
   ],
   "id": "167259b6ab96e5d8",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T06:48:14.308946Z",
     "start_time": "2024-10-16T06:48:14.202617Z"
    }
   },
   "source": [
    "from tensorflow.keras.applications import vgg16\n",
    "from omnixai.explainers.vision.specific.feature_visualization.visualizer import FeatureVisualizer"
   ],
   "id": "edae5880c64623cb",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapplications\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m vgg16\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01momnixai\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexplainers\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mvision\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mspecific\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfeature_visualization\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mvisualizer\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FeatureVisualizer\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we choose the VGG16 model for demonstration (you may test other CNN models, e.g., ResNet). The target layer is the layer to analyze."
   ],
   "id": "cf2d940a6717d2fd"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T06:48:17.050767Z",
     "start_time": "2024-10-16T06:48:17.040073Z"
    }
   },
   "source": [
    "model = vgg16.VGG16(weights='../../../data/feature-visualization/vgg16_weights_tf_dim_ordering_tf_kernels.h5', include_top=True, classes=1000)\n",
    "target_layer = model.layers[15]"
   ],
   "id": "629dc6db5e0cdad8",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vgg16' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mvgg16\u001B[49m\u001B[38;5;241m.\u001B[39mVGG16(weights\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../../../data/feature-visualization/vgg16_weights_tf_dim_ordering_tf_kernels.h5\u001B[39m\u001B[38;5;124m'\u001B[39m, include_top\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, classes\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000\u001B[39m)\n\u001B[1;32m      2\u001B[0m target_layer \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mlayers[\u001B[38;5;241m15\u001B[39m]\n",
      "\u001B[0;31mNameError\u001B[0m: name 'vgg16' is not defined"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first example is the \"layer\" objective, where we optimize the input image such that the average output of the layer is maximized."
   ],
   "id": "7e985742560e0903"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T06:48:18.719098Z",
     "start_time": "2024-10-16T06:48:18.710561Z"
    }
   },
   "source": [
    "optimizer = FeatureVisualizer(\n",
    "    model=model,\n",
    "    objectives=[{\"layer\": target_layer, \"type\": \"layer\"}]\n",
    ")\n",
    "explanations = optimizer.explain(\n",
    "    num_iterations=300,\n",
    "    image_shape=(224, 224)\n",
    ")\n",
    "explanations.ipython_plot()"
   ],
   "id": "47be46b8a02208d2",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FeatureVisualizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m \u001B[43mFeatureVisualizer\u001B[49m(\n\u001B[1;32m      2\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[1;32m      3\u001B[0m     objectives\u001B[38;5;241m=\u001B[39m[{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlayer\u001B[39m\u001B[38;5;124m\"\u001B[39m: target_layer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtype\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlayer\u001B[39m\u001B[38;5;124m\"\u001B[39m}]\n\u001B[1;32m      4\u001B[0m )\n\u001B[1;32m      5\u001B[0m explanations \u001B[38;5;241m=\u001B[39m optimizer\u001B[38;5;241m.\u001B[39mexplain(\n\u001B[1;32m      6\u001B[0m     num_iterations\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m300\u001B[39m,\n\u001B[1;32m      7\u001B[0m     image_shape\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m224\u001B[39m, \u001B[38;5;241m224\u001B[39m)\n\u001B[1;32m      8\u001B[0m )\n\u001B[1;32m      9\u001B[0m explanations\u001B[38;5;241m.\u001B[39mipython_plot()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'FeatureVisualizer' is not defined"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second example is the \"channel\" objective, where the input image is optimized such that the output of the specified channel is maximized."
   ],
   "id": "59305bd7f69537f"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T06:48:20.276857Z",
     "start_time": "2024-10-16T06:48:20.268303Z"
    }
   },
   "source": [
    "optimizer = FeatureVisualizer(\n",
    "    model=model,\n",
    "    objectives=[{\"layer\": target_layer, \"type\": \"channel\", \"index\": list(range(6))}]\n",
    ")\n",
    "explanations = optimizer.explain(\n",
    "    num_iterations=300,\n",
    "    image_shape=(224, 224)\n",
    ")\n",
    "explanations.ipython_plot()"
   ],
   "id": "65f893d0474c66",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FeatureVisualizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m \u001B[43mFeatureVisualizer\u001B[49m(\n\u001B[1;32m      2\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[1;32m      3\u001B[0m     objectives\u001B[38;5;241m=\u001B[39m[{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlayer\u001B[39m\u001B[38;5;124m\"\u001B[39m: target_layer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtype\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mchannel\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mindex\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m6\u001B[39m))}]\n\u001B[1;32m      4\u001B[0m )\n\u001B[1;32m      5\u001B[0m explanations \u001B[38;5;241m=\u001B[39m optimizer\u001B[38;5;241m.\u001B[39mexplain(\n\u001B[1;32m      6\u001B[0m     num_iterations\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m300\u001B[39m,\n\u001B[1;32m      7\u001B[0m     image_shape\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m224\u001B[39m, \u001B[38;5;241m224\u001B[39m)\n\u001B[1;32m      8\u001B[0m )\n\u001B[1;32m      9\u001B[0m explanations\u001B[38;5;241m.\u001B[39mipython_plot()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'FeatureVisualizer' is not defined"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also consider a combination of multiple objectives. The default weight for each objective is 1.0. We can set other weights as well."
   ],
   "id": "cba7c2b7101a877"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T14:07:43.431825Z",
     "start_time": "2024-10-10T14:07:43.431754Z"
    }
   },
   "source": [
    "optimizer = FeatureVisualizer(\n",
    "    model=model,\n",
    "    objectives=[\n",
    "        {\"layer\": target_layer, \"type\": \"layer\", \"weight\": 0.1},\n",
    "        {\"layer\": target_layer, \"type\": \"channel\", \"index\": list(range(6))}\n",
    "    ]\n",
    ")\n",
    "explanations = optimizer.explain(\n",
    "    num_iterations=300,\n",
    "    image_shape=(224, 224)\n",
    ")\n",
    "explanations.ipython_plot()"
   ],
   "id": "2600245e8e068902",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
