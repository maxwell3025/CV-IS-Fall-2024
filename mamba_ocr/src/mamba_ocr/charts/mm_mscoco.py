per_token_train_loss = [
    3.563575277104974,
    3.146849784689645,
    2.9307800728517273,
    2.709180945840975,
    2.589061432828506,
    2.5044817961752415,
    2.4407804487273097,
    2.389669311232865,
    2.3482861719094217,
    2.3061857097782195,
    2.2716150930306562,
    2.238436840241775,
    2.201756236686682,
    2.1733227353543043,
    2.135629180353135,
    2.1023114908020943,
    2.0644610674741366,
    2.034102242362375,
    1.9945339915963511,
    1.957705774422114,
]

in_context_accuracy = [
    0.23383084577114427,
    0.2537313432835821,
    0.27860696517412936,
    0.2935323383084577,
    0.3034825870646766,
    0.3034825870646766,
    0.3034825870646766,
    0.31343283582089554,
    0.31840796019900497,
    0.32338308457711445,
    0.32338308457711445,
    0.3034825870646766,
    0.30845771144278605,
    0.3034825870646766,
    0.3034825870646766,
    0.2935323383084577,
    0.2885572139303483,
    0.2835820895522388,
    0.2835820895522388,
    0.2885572139303483,
]

shuffled_accuracy = [
    0.25668449197860965,
    0.2774869109947644,
    0.31521739130434784,
    0.35978835978835977,
    0.3279569892473118,
    0.30386740331491713,
    0.3403141361256545,
    0.324468085106383,
    0.38857142857142857,
    0.3615023474178404,
    0.3315508021390374,
    0.3065326633165829,
    0.3407821229050279,
    0.328125,
    0.28717948717948716,
    0.359375,
    0.3672316384180791,
    0.36363636363636365,
    0.2905027932960894,
    0.3333333333333333,
]

import matplotlib.pyplot as plt

fig, ax = plt.subplots()

# Plot the data
ax.plot([epoch for epoch in range(1, 21)], in_context_accuracy, label="In-Context Accuracy")
ax.plot([epoch for epoch in range(1, 21)], shuffled_accuracy, label="Shuffled Accuracy")
ax.legend(loc='upper left')

# Customize the plot
ax.set_title("MedMamba Accuracy on MSOCO")
ax.set_xticks([epoch for epoch in range(1, 21)])
ax.set_xlabel("Epoch")
ax.set_ylabel("Accuracy")

# Show the plot
plt.show()