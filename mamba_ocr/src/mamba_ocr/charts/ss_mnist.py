per_token_train_loss = [
    1.2146514914929867,
    1.1436763280736548,
    1.129109991115651,
    1.0346104437817953,
    0.25814276438385214,
    0.05746678807586899,
    0.03244493816665844,
    0.010467030152905668,
    0.01303072906754364,
    0.01681599267531299,
    0.0011817862320095327,
    0.000534267952805629,
    0.017034683615711747,
    0.007802962305036536,
    0.007560067377866123,
    0.005748496471689053,
    0.0005910531892907578,
    7.804108571710497e-05,
    4.572383015880429e-05,
    2.9864511163046892e-05,
]

in_context_accuracy = [
    0.565625,
    0.5614583333333333,
    0.5708333333333333,
    0.8166666666666667,
    0.9604166666666667,
    0.99375,
    0.984375,
    1.0,
    1.0,
    0.9989583333333333,
    1.0,
    1.0,
    1.0,
    1.0,
    1.0,
    0.9989583333333333,
    1.0,
    1.0,
    1.0,
    1.0,
]

shuffled_accuracy = [
    0.571875,
    0.5677083333333334,
    0.5760416666666667,
    0.665625,
    0.7333333333333333,
    0.8020833333333334,
    0.7645833333333333,
    0.8177083333333334,
    0.8104166666666667,
    0.8416666666666667,
    0.8395833333333333,
    0.8572916666666667,
    0.7958333333333333,
    0.8666666666666667,
    0.871875,
    0.8260416666666667,
    0.8364583333333333,
    0.8489583333333334,
    0.8729166666666667,
    0.8541666666666666,
]

import matplotlib.pyplot as plt

fig, ax = plt.subplots()

# Plot the data
ax.plot([epoch for epoch in range(1, 21)], in_context_accuracy, label="In-Context Accuracy")
ax.plot([epoch for epoch in range(1, 21)], shuffled_accuracy, label="Shuffled Accuracy")
ax.legend(loc='upper left')

# Customize the plot
ax.set_title("Accuracy for Sequence Stacks")
ax.set_xticks([epoch for epoch in range(1, 21)])
ax.set_xlabel("Epoch")
ax.set_ylabel("Accuracy")

# Show the plot
plt.show()