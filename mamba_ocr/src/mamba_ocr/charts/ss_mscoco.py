per_token_train_loss = [
3.305173633620143,
2.9465401323201754,
2.688792798512926,
2.4914347965580723,
2.3377339931515357,
2.166621140902862,
1.9728304873375844,
2.1498143422262124,
1.723489187657833,
1.389003595279064,
1.1080395901808515,
0.9102602248215893,
0.7370050310370667,
0.6297056494543843,
0.517028809323771,
0.4383597686974099,
0.36929227315219276,
0.3149202240941425,
0.2947467866736891,
0.27473559225109057,
]

in_context_accuracy = [
0.263681592039801,
0.3034825870646766,
0.2935323383084577,
0.2935323383084577,
0.31840796019900497,
0.3034825870646766,
0.24875621890547264,
0.2885572139303483,
0.26865671641791045,
0.2935323383084577,
0.2885572139303483,
0.2835820895522388,
0.2835820895522388,
0.26865671641791045,
0.29850746268656714,
0.2835820895522388,
0.26865671641791045,
0.26865671641791045,
0.26865671641791045,
0.26865671641791045,
]

shuffled_accuracy = [
0.3010752688172043,
0.36923076923076925,
0.3389830508474576,
0.32124352331606215,
0.4148936170212766,
0.2879581151832461,
0.2857142857142857,
0.33689839572192515,
0.2722222222222222,
0.26229508196721313,
0.315,
0.29545454545454547,
0.30994152046783624,
0.3193717277486911,
0.2903225806451613,
0.3202247191011236,
0.35359116022099446,
0.3248730964467005,
0.3096446700507614,
0.3034825870646766,
]

import matplotlib.pyplot as plt

fig, ax = plt.subplots()

# Plot the data
ax.plot([epoch for epoch in range(1, 21)], in_context_accuracy, label="In-Context Accuracy")
ax.plot([epoch for epoch in range(1, 21)], shuffled_accuracy, label="Shuffled Accuracy")
ax.legend(loc='upper left')

# Customize the plot
ax.set_title("Sequence Stack Performance on MSOCO")
ax.set_xticks([epoch for epoch in range(1, 21)])
ax.set_xlabel("Epoch")
ax.set_ylabel("Accuracy")

# Show the plot
plt.show()